<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>Blog: We don&#x27;t call it &quot;AI&quot; | Apsis Labs</title><meta name="description" content="&lt;p&gt;I quipped today with a colleague that LLM meant &amp;quot;large lying machine&amp;quot; and I was only half joking. We were discussing the merits of the hype surrounding features (and whole startups) that effectively wrap the OpenAI API, and how much long-term success can be expected when your value add is saving time typing the prompt into ChatGPT. Here at Apsis, we tend to believe that generative models like ChatGPT or llama are best suited to augment foundationally sound products: that is, to add summaries or shortcuts to an application that already offers value &lt;em&gt;without&lt;/em&gt; the GPT integration.&lt;/p&gt;
&lt;p&gt;This conversation, and others like it, though, have had me thinking about another little quirk around the proverbial offices here at Apsis --- something you may have noticed in the previous paragraph: we don&amp;#39;t call it AI.&lt;/p&gt;
&lt;p&gt;It&amp;#39;s a quirk, I think, not born out of elitism or pedantry or disdain&lt;/p&gt;
"/><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"/><link rel="manifest" href="/site.webmanifest"/><meta name="description" content="&lt;p&gt;I quipped today with a colleague that LLM meant &amp;quot;large lying machine&amp;quot; and I was only half joking. We were discussing the merits of the hype surrounding features (and whole startups) that effectively wrap the OpenAI API, and how much long-term success can be expected when your value add is saving time typing the prompt into ChatGPT. Here at Apsis, we tend to believe that generative models like ChatGPT or llama are best suited to augment foundationally sound products: that is, to add summaries or shortcuts to an application that already offers value &lt;em&gt;without&lt;/em&gt; the GPT integration.&lt;/p&gt;
&lt;p&gt;This conversation, and others like it, though, have had me thinking about another little quirk around the proverbial offices here at Apsis --- something you may have noticed in the previous paragraph: we don&amp;#39;t call it AI.&lt;/p&gt;
&lt;p&gt;It&amp;#39;s a quirk, I think, not born out of elitism or pedantry or disdain&lt;/p&gt;
"/><meta property="og:url" content="https://apsis.io"/><meta property="og:type" content="website"/><meta property="og:title" content="Blog: We don&#x27;t call it &quot;AI&quot;"/><meta property="og:description" content="&lt;p&gt;I quipped today with a colleague that LLM meant &amp;quot;large lying machine&amp;quot; and I was only half joking. We were discussing the merits of the hype surrounding features (and whole startups) that effectively wrap the OpenAI API, and how much long-term success can be expected when your value add is saving time typing the prompt into ChatGPT. Here at Apsis, we tend to believe that generative models like ChatGPT or llama are best suited to augment foundationally sound products: that is, to add summaries or shortcuts to an application that already offers value &lt;em&gt;without&lt;/em&gt; the GPT integration.&lt;/p&gt;
&lt;p&gt;This conversation, and others like it, though, have had me thinking about another little quirk around the proverbial offices here at Apsis --- something you may have noticed in the previous paragraph: we don&amp;#39;t call it AI.&lt;/p&gt;
&lt;p&gt;It&amp;#39;s a quirk, I think, not born out of elitism or pedantry or disdain&lt;/p&gt;
"/><meta property="og:image" content="https://apsis.io/social.jpg"/><meta name="twitter:card" content="summary_large_image"/><meta property="twitter:domain" content="apsis.io"/><meta property="twitter:url" content="https://apsis.io"/><meta name="twitter:title" content="Blog: We don&#x27;t call it &quot;AI&quot;"/><meta name="twitter:description" content="&lt;p&gt;I quipped today with a colleague that LLM meant &amp;quot;large lying machine&amp;quot; and I was only half joking. We were discussing the merits of the hype surrounding features (and whole startups) that effectively wrap the OpenAI API, and how much long-term success can be expected when your value add is saving time typing the prompt into ChatGPT. Here at Apsis, we tend to believe that generative models like ChatGPT or llama are best suited to augment foundationally sound products: that is, to add summaries or shortcuts to an application that already offers value &lt;em&gt;without&lt;/em&gt; the GPT integration.&lt;/p&gt;
&lt;p&gt;This conversation, and others like it, though, have had me thinking about another little quirk around the proverbial offices here at Apsis --- something you may have noticed in the previous paragraph: we don&amp;#39;t call it AI.&lt;/p&gt;
&lt;p&gt;It&amp;#39;s a quirk, I think, not born out of elitism or pedantry or disdain&lt;/p&gt;
"/><meta name="twitter:image" content="https://apsis.io/social.jpg"/><meta name="next-head-count" content="3"/><link rel="preload" href="/_next/static/media/a34f9d1faa5f3315-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/a9387c470a117487-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/37e85b36581a02ab-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/3478b6abef19b3b3-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/035951aefad7b653-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/css/eb18153a0a375343.css" as="style"/><link rel="stylesheet" href="/_next/static/css/eb18153a0a375343.css" data-n-g=""/><link rel="preload" href="/_next/static/css/01bbc1cf78aab92b.css" as="style"/><link rel="stylesheet" href="/_next/static/css/01bbc1cf78aab92b.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/_next/static/chunks/webpack-38cee4c0e358b1a3.js" defer=""></script><script src="/_next/static/chunks/framework-64ad27b21261a9ce.js" defer=""></script><script src="/_next/static/chunks/main-58eb4e77e43e295f.js" defer=""></script><script src="/_next/static/chunks/pages/_app-2003168507d95f21.js" defer=""></script><script src="/_next/static/chunks/25-c9e36e11cdefe32e.js" defer=""></script><script src="/_next/static/chunks/444-5d99c14f07dd0b60.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5Byear%5D/%5Bmonth%5D/%5Bday%5D/%5Bslug%5D-97e1c6e54593dd15.js" defer=""></script><script src="/_next/static/v720CVXUIWa9VDkbWKXrW/_buildManifest.js" defer=""></script><script src="/_next/static/v720CVXUIWa9VDkbWKXrW/_ssgManifest.js" defer=""></script><style id="__jsx-1589735335">:root{--font-inter:'__Inter_d65c78', '__Inter_Fallback_d65c78';--font-mono:'__IBM_Plex_Mono_191acc', '__IBM_Plex_Mono_Fallback_191acc'}</style></head><body><div id="__next"><section class="Section_section__rDOJq Section_section--bordered__v_Az0"><div class="Section_section__mask__iGDmr"></div><div class="Section_section__container__9Fwqr"><div class="Section_section__content__Klb0i"><nav class="Navbar_navbar__pYr0W"><a class="Navbar_navbar__logo__NNGhf" href="/"><h1 class="LogoType_logotype__iHLMP"><svg viewBox="0 0 64 64" fill="none" xmlns="http://www.w3.org/2000/svg" class="LogoType_logotype__planet__674Ub" width="24" height="24"><path fill-rule="evenodd" clip-rule="evenodd" d="M32 64C49.6731 64 64 49.6731 64 32C64 14.3269 49.6731 0 32 0C14.3269 0 0 14.3269 0 32C0 49.6731 14.3269 64 32 64ZM32 61C48.0163 61 61 48.0163 61 32C61 15.9837 48.0163 3 32 3C15.9837 3 3 15.9837 3 32C3 48.0163 15.9837 61 32 61ZM58 32C58 46.3594 46.3594 58 32 58C17.6406 58 6 46.3594 6 32C6 17.6406 17.6406 6 32 6C46.3594 6 58 17.6406 58 32ZM44 26C47.3137 26 50 23.3137 50 20C50 16.6863 47.3137 14 44 14C40.6863 14 38 16.6863 38 20C38 23.3137 40.6863 26 44 26Z" fill="currentColor"></path></svg>Apsis Labs</h1></a><nav class="Navbar_navbar__nav__YFZzV"><a class="Navbar_navbar__nav_item__OpfdQ" href="/">Home</a><a class="Navbar_navbar__nav_item__OpfdQ" href="/blog/">Blog</a></nav></nav></div></div></section><section class="Section_section__rDOJq Section_section--spaced__Ihmp2 Section_section--narrow__GIboH"><div class="Section_section__mask__iGDmr"></div><div class="Section_section__container__9Fwqr"><div class="Section_section__content__Klb0i"><div class="Post_post-wrapper__s850H"><article class="Post_post__m_Xor" itemType="http://schema.org/BlogPosting"><header class="Post_post__header__pEZ4C"><div><h1 class="Post_post__title__eUeKR"><a href="/blog/2024/09/24/its-not-ai/">We don&#x27;t call it &quot;AI&quot;</a></h1><footer class="Post_post__meta__j55Gy">Posted on<!-- --> <time dateTime="2024-09-24" itemProp="datePublished">2024-09-24</time> <!-- -->by<!-- --> <span itemProp="author" itemscope="" itemType="http://schema.org/Person"><span itemProp="name">wyatt</span></span></footer></div><div class="Post_post__image-wrapper__mjNlP"><img src="/img/posts/crows.png" alt="We don&#x27;t call it &quot;AI&quot;" class="Post_post__image__Dbjks" data-action="zoom"/></div></header><div class="Post_post__content__SHRW1"><p>I quipped today with a colleague that LLM meant &quot;large lying machine&quot; and I was only half joking. We were discussing the merits of the hype surrounding features (and whole startups) that effectively wrap the OpenAI API, and how much long-term success can be expected when your value add is saving time typing the prompt into ChatGPT. Here at Apsis, we tend to believe that generative models like ChatGPT or llama are best suited to augment foundationally sound products: that is, to add summaries or shortcuts to an application that already offers value <em>without</em> the GPT integration.</p>
<p>This conversation, and others like it, though, have had me thinking about another little quirk around the proverbial offices here at Apsis --- something you may have noticed in the previous paragraph: we don&#39;t call it AI.</p>
<p>It&#39;s a quirk, I think, not born out of elitism or pedantry or disdain. It&#39;s not fear for the future of our jobs (though there are doomsayers a plenty if you care to listen). Rather, if you&#39;ve worked with us, you&#39;ll know how highly we prize clear communication. Clarity in transmission of meaning is, in many ways, the most fundamental aspect of a programmer&#39;s job: we provide instruction to the machine which cannot help but take all instructions literally. Our role as contractors is not much different: we are often brought in because our clients value our expertise and lack it themselves. They trust us --- hell, they pay us --- to be the liaison between the technical and the non-technical, and to call this current generation of predictive models &quot;AI&quot; betrays that trust.</p>
<p>See, &quot;AI&quot; conjures HAL 9000 and Skynet, Deep Thought and the Prime Radiant. What it does not do is convey to our clients what is actually happening: a recursive loop of predicting the next word in a sentence based on dubiously procured sources.<sup><a id="footnote-ref-1" href="#footnote-1" data-footnote-ref aria-describedby="footnote-label">1</a></sup> A great flattener of the creative into the most or second most likely thought. There are situations in which that is useful, productive, efficient: but there are many more applications in which it is harmful and misleading. Math (hard math, no doubt) gussied up as the future promised us by a century of science fiction.</p>
<p>So we don&#39;t call it AI. To do so cedes our credibility to the marketers --- and we can&#39;t have that.</p>
<section class="footnotes" data-footnotes>
<h2 id="footnote-label" class="sr-only">Footnotes</h2>
<ol>
<li id="footnote-1">
<p>This is, I know, a massive oversimplification. I&#39;ll defer an actual explanation of the inner workings of generative pre-trained models to the always phenomenal <a href="https://www.3blue1brown.com/topics/neural-networks">Three Blue One Brown</a> <a href="#footnote-ref-1" data-footnote-backref aria-label="Back to reference 1">↩</a></p>
</li>
</ol>
</section>
</div><footer class="Post_post__meta__j55Gy">Posted on<!-- --> <time dateTime="2024-09-24" itemProp="datePublished">2024-09-24</time> <!-- -->by<!-- --> <span itemProp="author" itemscope="" itemType="http://schema.org/Person"><span itemProp="name">wyatt</span></span></footer></article></div></div></div></section><section class="Section_section__rDOJq Section_section--gray__Xj11z Section_section--bordered__v_Az0"><div class="Section_section__mask__iGDmr"><div class="Section_section__guides__rCsOH"></div></div><div class="Section_section__container__9Fwqr"><div class="Section_section__content__Klb0i"><footer class="Footer_footer__W37AO"><div class="Row_row__1wkRY Row_row--top__qt9xi"><div><a class="Footer_footer__logo__G9sAT" href="/"><h1 class="LogoType_logotype__iHLMP Footer_footer__logotype__Olnhi"><svg viewBox="0 0 64 64" fill="none" xmlns="http://www.w3.org/2000/svg" class="LogoType_logotype__planet__674Ub" width="18" height="18"><path fill-rule="evenodd" clip-rule="evenodd" d="M32 64C49.6731 64 64 49.6731 64 32C64 14.3269 49.6731 0 32 0C14.3269 0 0 14.3269 0 32C0 49.6731 14.3269 64 32 64ZM32 61C48.0163 61 61 48.0163 61 32C61 15.9837 48.0163 3 32 3C15.9837 3 3 15.9837 3 32C3 48.0163 15.9837 61 32 61ZM58 32C58 46.3594 46.3594 58 32 58C17.6406 58 6 46.3594 6 32C6 17.6406 17.6406 6 32 6C46.3594 6 58 17.6406 58 32ZM44 26C47.3137 26 50 23.3137 50 20C50 16.6863 47.3137 14 44 14C40.6863 14 38 16.6863 38 20C38 23.3137 40.6863 26 44 26Z" fill="currentColor"></path></svg>Apsis Labs</h1></a><small><ul role="list" class="inline_list"><li>Copyright <!-- -->2024<!-- --> Apsis Labs, LLP</li><li><a class="link" target="_blank" href="https://github.com/apsislabs">Github</a></li><li><a class="link" target="_blank" href="https://www.linkedin.com/company/apsislabs/">LinkedIn</a></li><li><a class="link" href="mailto:contact@apsis.io">contact@apsis.io</a></li></ul></small><small><ul role="list" class="inline_list"><li><a class="link" href="/privacy/">Privacy Policy</a></li><li><a class="link" href="/conduct/">Code of Conduct</a></li><li><a class="link" href="/mdbn/">Data Breach Notification Policy</a></li></ul></small></div><div class="Footer_footer__tagline_container__19nxT"><h4 class="Footer_footer__tagline__gO_GO">Distributed &amp; Horizontally Scalable</h4><small><ul class="inline_list"><li>❤️ from:</li><li>Seattle</li><li>Boulder</li><li>Boston</li><li>Portland</li><li>Hartford</li></ul></small></div></div></footer></div></div></section></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"postData":{"id":"its-not-ai","href":{"pathname":"/blog/[year]/[month]/[day]/[slug]","query":{"year":"2024","month":"09","day":"24","slug":"its-not-ai"}},"contentHtml":"\u003cp\u003eI quipped today with a colleague that LLM meant \u0026quot;large lying machine\u0026quot; and I was only half joking. We were discussing the merits of the hype surrounding features (and whole startups) that effectively wrap the OpenAI API, and how much long-term success can be expected when your value add is saving time typing the prompt into ChatGPT. Here at Apsis, we tend to believe that generative models like ChatGPT or llama are best suited to augment foundationally sound products: that is, to add summaries or shortcuts to an application that already offers value \u003cem\u003ewithout\u003c/em\u003e the GPT integration.\u003c/p\u003e\n\u003cp\u003eThis conversation, and others like it, though, have had me thinking about another little quirk around the proverbial offices here at Apsis --- something you may have noticed in the previous paragraph: we don\u0026#39;t call it AI.\u003c/p\u003e\n\u003cp\u003eIt\u0026#39;s a quirk, I think, not born out of elitism or pedantry or disdain. It\u0026#39;s not fear for the future of our jobs (though there are doomsayers a plenty if you care to listen). Rather, if you\u0026#39;ve worked with us, you\u0026#39;ll know how highly we prize clear communication. Clarity in transmission of meaning is, in many ways, the most fundamental aspect of a programmer\u0026#39;s job: we provide instruction to the machine which cannot help but take all instructions literally. Our role as contractors is not much different: we are often brought in because our clients value our expertise and lack it themselves. They trust us --- hell, they pay us --- to be the liaison between the technical and the non-technical, and to call this current generation of predictive models \u0026quot;AI\u0026quot; betrays that trust.\u003c/p\u003e\n\u003cp\u003eSee, \u0026quot;AI\u0026quot; conjures HAL 9000 and Skynet, Deep Thought and the Prime Radiant. What it does not do is convey to our clients what is actually happening: a recursive loop of predicting the next word in a sentence based on dubiously procured sources.\u003csup\u003e\u003ca id=\"footnote-ref-1\" href=\"#footnote-1\" data-footnote-ref aria-describedby=\"footnote-label\"\u003e1\u003c/a\u003e\u003c/sup\u003e A great flattener of the creative into the most or second most likely thought. There are situations in which that is useful, productive, efficient: but there are many more applications in which it is harmful and misleading. Math (hard math, no doubt) gussied up as the future promised us by a century of science fiction.\u003c/p\u003e\n\u003cp\u003eSo we don\u0026#39;t call it AI. To do so cedes our credibility to the marketers --- and we can\u0026#39;t have that.\u003c/p\u003e\n\u003csection class=\"footnotes\" data-footnotes\u003e\n\u003ch2 id=\"footnote-label\" class=\"sr-only\"\u003eFootnotes\u003c/h2\u003e\n\u003col\u003e\n\u003cli id=\"footnote-1\"\u003e\n\u003cp\u003eThis is, I know, a massive oversimplification. I\u0026#39;ll defer an actual explanation of the inner workings of generative pre-trained models to the always phenomenal \u003ca href=\"https://www.3blue1brown.com/topics/neural-networks\"\u003eThree Blue One Brown\u003c/a\u003e \u003ca href=\"#footnote-ref-1\" data-footnote-backref aria-label=\"Back to reference 1\"\u003e↩\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/section\u003e\n","layout":"post","author":"wyatt","title":"We don't call it \"AI\"","image":"/img/posts/crows.png","excerpt":"\u003cp\u003eI quipped today with a colleague that LLM meant \u0026quot;large lying machine\u0026quot; and I was only half joking. We were discussing the merits of the hype surrounding features (and whole startups) that effectively wrap the OpenAI API, and how much long-term success can be expected when your value add is saving time typing the prompt into ChatGPT. Here at Apsis, we tend to believe that generative models like ChatGPT or llama are best suited to augment foundationally sound products: that is, to add summaries or shortcuts to an application that already offers value \u003cem\u003ewithout\u003c/em\u003e the GPT integration.\u003c/p\u003e\n\u003cp\u003eThis conversation, and others like it, though, have had me thinking about another little quirk around the proverbial offices here at Apsis --- something you may have noticed in the previous paragraph: we don\u0026#39;t call it AI.\u003c/p\u003e\n\u003cp\u003eIt\u0026#39;s a quirk, I think, not born out of elitism or pedantry or disdain\u003c/p\u003e\n","date":"2024-09-24"}},"__N_SSG":true},"page":"/blog/[year]/[month]/[day]/[slug]","query":{"year":"2024","month":"09","day":"24","slug":"its-not-ai"},"buildId":"v720CVXUIWa9VDkbWKXrW","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>