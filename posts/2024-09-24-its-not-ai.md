---
layout: post
author: wyatt
title: We don't call it "AI"
image: "/img/posts/crows.png"
excerpt:
date: 2024-09-24
---

I quipped today with a colleague that LLM meant "large lying machine" and I was only half joking. We were discussing the merits of the hype surrounding features (and whole startups) that effectively wrap the OpenAI API, and how much long-term success can be expected when your value add is saving time typing the prompt into ChatGPT. Here at Apsis, we tend to believe that generative models like ChatGPT or llama are best suited to augment foundationally sound products: that is, to add summaries or shortcuts to an application that already offers value _without_ the GPT integration.

This conversation, and others like it, though, have had me thinking about another little quirk around the proverbial offices here at Apsis --- something you may have noticed in the previous paragraph: we don't call it AI.

It's a quirk, I think, not born out of elitism or pedantry or disdain. It's not fear for the future of our jobs (though there are doomsayers a plenty if you care to listen). Rather, if you've worked with us, you'll know how highly we prize clear communication. Clarity in transmission of meaning is, in many ways, the most fundamental aspect of a programmer's job: we provide instruction to the machine which cannot help but take all instructions literally. Our role as contractors is not much different: we are often brought in because our clients value our expertise and lack it themselves. They trust us --- hell, they pay us --- to be the liaison between the technical and the non-technical, and to call this current generation of predictive models "AI" betrays that trust.

See, "AI" conjures HAL 9000 and Skynet, Deep Thought and the Prime Radiant. What it does not do is convey to our clients what is actually happening: a recursive loop of predicting the next word in a sentence based on dubiously procured sources.[^1] A great flattener of the creative into the most or second most likely thought. There are situations in which that is useful, productive, efficient: but there are many more applications in which it is harmful and misleading. Math (hard math, no doubt) gussied up as the future promised us by a century of science fiction.

So we don't call it AI. To do so cedes our credibility to the marketers --- and we can't have that.


[^1]: This is, I know, a massive oversimplification. I'll defer an actual explanation of the inner workings of generative pre-trained models to the always phenomenal [Three Blue One Brown](https://www.3blue1brown.com/topics/neural-networks)